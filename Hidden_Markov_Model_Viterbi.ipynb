{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a57afe",
   "metadata": {
    "id": "51a57afe"
   },
   "source": [
    "# Building and Evaluating a Hidden Markov Model and a Viterbi Algorithm in NLP\n",
    "\n",
    "## By Brea Koenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2ebeb",
   "metadata": {
    "id": "6fd2ebeb"
   },
   "source": [
    "### Overview\n",
    "Build and evaluate a Hidden Markov Model (HMM) with a Viterbi algorithm in the field of Natural Language Processing (NLP). Use the Brown corpus from the NLTK library, focusing on the categories 'news', 'editorial', and 'reviews' with a 'universal' tagset. The purpose is to implement these fundamental concepts in NLP and to understand their applications and limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18180696",
   "metadata": {
    "id": "18180696"
   },
   "source": [
    "\n",
    "## Preparing the Environment\n",
    "\n",
    "Import the necessary libraries. I use NLTK for accessing linguistic data and algorithms, including the Brown corpus, and `train_test_split` from `sklearn.model_selection` for splitting data. The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University.\n",
    "\n",
    "This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "045303a7-7e4a-4cf8-a3e5-f2c9bcf34f17",
   "metadata": {
    "id": "045303a7-7e4a-4cf8-a3e5-f2c9bcf34f17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04166d-5394-4cf5-83c1-a073dda1c9fe",
   "metadata": {
    "id": "ca04166d-5394-4cf5-83c1-a073dda1c9fe"
   },
   "source": [
    "\n",
    "## Loading and Exploring the Data\n",
    "\n",
    "Load the 'Brown' corpus, focusing on specific categories: 'news', 'editorial', and 'reviews'. We'll use the 'universal' tagset for a more generalizable analysis. Utilize `brown.tagged_sents(categories=['news', 'editorial', 'reviews'], tagset='universal')` to load the data.\n",
    "\n",
    "The **universal** tagset is a simplified schema developed to facilitate the comparison of grammatical categories across different languages. This tagset includes categories like:\n",
    "\n",
    "    NOUN (noun)\n",
    "    VERB (verb)\n",
    "    ADJ (adjective)\n",
    "    ADV (adverb)\n",
    "    PRON (pronoun)\n",
    "    DET (determiner, includes articles and quantifiers)\n",
    "    ADP (adposition, includes prepositions and postpositions)\n",
    "    NUM (numeral)\n",
    "    CONJ (conjunction)\n",
    "    PRT (particle, includes small function words like 'to' that are not clearly categorized under the above)\n",
    "    . (punctuation)\n",
    "    X (other category, including undefined and erroneous cases)\n",
    "\n",
    "The `tagged_sents()` returns a list comprised of sentences, where each sentence is another list of word-tag pairs. Each pair consists of a word from the sentence and its corresponding part-of-speech tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f5971e-b5ef-4718-ac6d-f949d9f18583",
   "metadata": {
    "id": "80f5971e-b5ef-4718-ac6d-f949d9f18583",
    "tags": []
   },
   "outputs": [],
   "source": [
    "brown.tagged_sents(categories=['news', 'editorial', 'reviews'], tagset='universal')\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories=['news', 'editorial', 'reviews'], tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d044df-f068-4ca7-8350-060a4f7ef701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bf573",
   "metadata": {
    "id": "af8bf573"
   },
   "source": [
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "For the Hidden Markov Model, preprocess the data to ensure consistency and effectiveness. Apply lowercasing to each word in the (word, tag) tuples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f19875-6f58-40b2-b743-03cff77b56a1",
   "metadata": {
    "id": "83f19875-6f58-40b2-b743-03cff77b56a1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('the', 'DET'),\n",
       "  ('fulton', 'NOUN'),\n",
       "  ('county', 'NOUN'),\n",
       "  ('grand', 'ADJ'),\n",
       "  ('jury', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('friday', 'NOUN'),\n",
       "  ('an', 'DET'),\n",
       "  ('investigation', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  (\"atlanta's\", 'NOUN'),\n",
       "  ('recent', 'ADJ'),\n",
       "  ('primary', 'NOUN'),\n",
       "  ('election', 'NOUN'),\n",
       "  ('produced', 'VERB'),\n",
       "  ('``', '.'),\n",
       "  ('no', 'DET'),\n",
       "  ('evidence', 'NOUN'),\n",
       "  (\"''\", '.'),\n",
       "  ('that', 'ADP'),\n",
       "  ('any', 'DET'),\n",
       "  ('irregularities', 'NOUN'),\n",
       "  ('took', 'VERB'),\n",
       "  ('place', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents_lower = [\n",
    "    [(word.lower(),tag) for word, tag in sentence]\n",
    "    for sentence in brown_tagged_sents]\n",
    "\n",
    "brown_tagged_sents_lower[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43719399-7ec5-4199-9bb3-ed34cf6e57c0",
   "metadata": {
    "id": "43719399-7ec5-4199-9bb3-ed34cf6e57c0"
   },
   "source": [
    "## Split Train and Test\n",
    "\n",
    "Using train_test_split from sklearn, split the dataset from the previous step into train and test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15afefb-d468-4023-a554-4feaf172bd08",
   "metadata": {
    "id": "e15afefb-d468-4023-a554-4feaf172bd08"
   },
   "outputs": [],
   "source": [
    "train_sents, test_sents = train_test_split(brown_tagged_sents_lower,\n",
    "                                           test_size=0.2, # 80/20 split\n",
    "                                           random_state=42\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa3d97-3117-4184-8c2c-c3265d34da13",
   "metadata": {
    "id": "8efa3d97-3117-4184-8c2c-c3265d34da13"
   },
   "source": [
    "\n",
    "## Training the Hidden Markov Model with Viterbi\n",
    "\n",
    "Construct a dictionary of words in the form of a python list that includes every unique word found in the training set. Follow the same process for the tags set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d77cf74a-adc2-42e4-9baa-76eaf4b8a0e8",
   "metadata": {
    "id": "d77cf74a-adc2-42e4-9baa-76eaf4b8a0e8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract words and tags from training set\n",
    "train_words = [word for sentence in train_sents for word, _ in sentence]\n",
    "train_tags = [tag for sentence in train_sents for _, tag in sentence]\n",
    "\n",
    "# Create vobab of unique words and tags\n",
    "vocabulary = list(set(train_words))\n",
    "tag_set = list(set(train_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed34abc-8814-4b55-a2e8-516cb9827131",
   "metadata": {
    "id": "0ed34abc-8814-4b55-a2e8-516cb9827131"
   },
   "source": [
    "For building the Hidden Markov Model (HMM), utilize the [`HiddenMarkovModelTrainer`](https://tedboy.github.io/nlps/generated/generated/nltk.HiddenMarkovModelTrainer.html) class from NLTK.  \n",
    "\n",
    "This class encapsulates [**both the HMM and the Viterbi algorithm**](https://www.nltk.org/api/nltk.tag.hmm.html). The Viterbi algorithm is used here to determine the most likely sequence of tags (states) for a given sequence of words (observations), based on the probabilities learned by the HMM. It's essential to import the `HiddenMarkovModelTrainer` from nltk.tag for this purpose.\n",
    "\n",
    "Create an object from the `HiddenMarkovModelTrainer` using the tag set list and the dictionary list created before. This object will be used to train our HMM models.\n",
    "\n",
    "Train five different HMM models:\n",
    "\n",
    "- A 'pure' HMM without smoothing (For more about Smoothing, read chapter three of this [thesis](https://digitalscholarship.unlv.edu/cgi/viewcontent.cgi?article=2008&context=thesesdissertations#:~:text=Smoothing%20techniques%20in%20HMM%20will,to%20produce%20more%20accurate%20probabilities.))\n",
    "\n",
    "    Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing only the 'train' dataset\n",
    "    \n",
    "    \n",
    "- HMM with [LidstoneProbDist](https://en.wikipedia.org/wiki/Additive_smoothing) smoothing and gamma = 0.01\n",
    "\n",
    "     LidstoneProbDist is an implementation of a Lidstone probability distribution, which is a variant of the Laplace distribution. The gamma parameter is the smoothing factor. The value of gamma determines the degree of smoothing applied. It's generally a positive number. A gamma of 1 corresponds to Laplace smoothing (add-one), while values different from 1 indicate different degrees of smoothing\n",
    "     \n",
    "     Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing the 'train' dataset and\n",
    "     supplied function `lidstone_prob_dist_001`\n",
    "     \n",
    "     \n",
    "- HMM with [LidstoneProbDist](https://en.wikipedia.org/wiki/Additive_smoothing) smoothing and gamma = 0.1\n",
    "    \n",
    "    Same as above, but with different gamma value.\n",
    "\n",
    "    Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing the 'train' dataset and the suplied function `lidstone_prob_dist_01`\n",
    "    \n",
    "    \n",
    "- HMM with [MLEProbDist (Maximum Likelihood Estimation)](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)\n",
    "\n",
    "    The basic idea of MLE is to choose the parameters of a model in such a way that the likelihood (probability) of the observed data is maximized. In other words, MLE seeks the parameter values that make the observed data most probable.\n",
    "     \n",
    "    Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing the 'train' dataset and  the suplied function `MLE_ProbDist`\n",
    "    \n",
    "     \n",
    "- HMM with [ELEProbDist (Expected Likelihood Estimation)](https://machinelearningmastery.com/what-is-maximum-likelihood-estimation-in-machine-learning/)\n",
    "\n",
    "    This method is a form of statistical smoothing, similar to LidstoneProbDist and LaplaceProbDist, but with a slightly different approach.\n",
    "\n",
    "    The idea behind ELE smoothing is to adjust probabilities in a way that balances accuracy in modeling frequently occurring events with the capability to handle rare or unobserved events. In simple terms, ELE smoothing attempts to estimate the probability of future events based on observed frequency, making adjustments to ensure that unobserved events are not given a probability of zero.\n",
    "     \n",
    "    Train a model using the HiddenMarkovModelTrainer object (train_supervised method), passing the 'train' dataset and the suplied function `ELE_ProbDist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "705afa5d-33a1-4070-8eab-74be1093531b",
   "metadata": {
    "id": "705afa5d-33a1-4070-8eab-74be1093531b"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import LidstoneProbDist, MLEProbDist, ELEProbDist\n",
    "\n",
    "def lidstone_prob_dist_001(fd, bins):\n",
    "    return LidstoneProbDist(fd, 0.01)\n",
    "\n",
    "def lidstone_prob_dist_01(fd, bins):\n",
    "    return LidstoneProbDist(fd, 0.1)\n",
    "\n",
    "def MLE_ProbDist(fd, bins):\n",
    "    return MLEProbDist(fd)\n",
    "\n",
    "def ELE_ProbDist(fd, bins):\n",
    "    return ELEProbDist(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5e8c824-bcdb-49eb-a547-f62288ea94fd",
   "metadata": {
    "id": "e5e8c824-bcdb-49eb-a547-f62288ea94fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary modules from NLTK for HMM training and probability distributions\n",
    "from nltk.tag import HiddenMarkovModelTrainer\n",
    "from nltk.probability import LidstoneProbDist, MLEProbDist, ELEProbDist\n",
    "\n",
    "# Create trainer\n",
    "trainer = HiddenMarkovModelTrainer(states=tag_set,symbols=vocabulary)\n",
    "\n",
    "# Model 1\n",
    "hmm_pure = trainer.train_supervised(train_sents)\n",
    "\n",
    "# Model 2\n",
    "hmm_lidstone_001 = trainer.train_supervised(train_sents, estimator=lidstone_prob_dist_001)\n",
    "\n",
    "# Model 3\n",
    "hmm_lidstone_01 = trainer.train_supervised(train_sents, estimator=lidstone_prob_dist_01)\n",
    "\n",
    "# Model 4\n",
    "hmm_mle = trainer.train_supervised(train_sents,estimator=MLE_ProbDist)\n",
    "\n",
    "# Model 5\n",
    "hmm_ele = trainer.train_supervised(train_sents,estimator=ELE_ProbDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77509b8-0848-4a26-b5ae-be6d716fcad4",
   "metadata": {
    "id": "b77509b8-0848-4a26-b5ae-be6d716fcad4"
   },
   "source": [
    "## Applying the HMM with Viterbi Algorithm\n",
    "\n",
    "Predict the tags from the 'test' dataset using **each of the models created before**.\n",
    "\n",
    "Use the `best_path` (docs [here](https://www.nltk.org/api/nltk.tag.hmm.html#nltk.tag.hmm.HiddenMarkovModelTagger.best_path)) function from the model. This function is used to predict the most likely sequence of tags for the given sequence of words. The `best_path` takes an unlabelled (without tags) sentence and returns a sequence of predicted tags.\n",
    "\n",
    "Make sure to 'break' the 'test' dataset and use only the sentence (without tags) part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0f98b0c-44d7-4017-bcdb-d13010e4e208",
   "metadata": {
    "id": "a0f98b0c-44d7-4017-bcdb-d13010e4e208",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting tags with Pure HMM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/nltk/tag/hmm.py:335: RuntimeWarning: overflow encountered in cast\n",
      "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
      "/opt/anaconda3/lib/python3.12/site-packages/nltk/tag/hmm.py:333: RuntimeWarning: overflow encountered in cast\n",
      "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
      "/opt/anaconda3/lib/python3.12/site-packages/nltk/tag/hmm.py:363: RuntimeWarning: overflow encountered in cast\n",
      "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction with Pure HMM completed.\n",
      "\n",
      "Predicting tags with HMM (Lidstone, gamma=0.01)...\n",
      "Prediction with HMM (Lidstone, gamma=0.01) completed.\n",
      "\n",
      "Predicting tags with HMM (Lidstone, gamma=0.1)...\n",
      "Prediction with HMM (Lidstone, gamma=0.1) completed.\n",
      "\n",
      "Predicting tags with HMM (MLEProbDist)...\n",
      "Prediction with HMM (MLEProbDist) completed.\n",
      "\n",
      "Predicting tags with HMM (ELEProbDist)...\n",
      "Prediction with HMM (ELEProbDist) completed.\n"
     ]
    }
   ],
   "source": [
    "# Break the test dataset to use only the sentences (words) without tags\n",
    "test_sentences = [[word for word, tag in sentence] for sentence in test_sents]\n",
    "\n",
    "# Predict tags for the test dataset using each model\n",
    "# Model 1: Pure HMM\n",
    "print(\"\\nPredicting tags with Pure HMM...\")\n",
    "predicted_pure = [hmm_pure.tag(sentence) for sentence in test_sentences]\n",
    "print(\"Prediction with Pure HMM completed.\")\n",
    "\n",
    "# Model 2: HMM with Lidstone smoothing (gamma=0.01)\n",
    "print(\"\\nPredicting tags with HMM (Lidstone, gamma=0.01)...\")\n",
    "predicted_lidstone_001 = [hmm_lidstone_001.tag(sentence) for sentence in test_sentences]\n",
    "print(\"Prediction with HMM (Lidstone, gamma=0.01) completed.\")\n",
    "\n",
    "# Model 3: HMM with Lidstone smoothing (gamma=0.1)\n",
    "print(\"\\nPredicting tags with HMM (Lidstone, gamma=0.1)...\")\n",
    "predicted_lidstone_01 = [hmm_lidstone_01.tag(sentence) for sentence in test_sentences]\n",
    "print(\"Prediction with HMM (Lidstone, gamma=0.1) completed.\")\n",
    "\n",
    "# Model 4: HMM with MLEProbDist\n",
    "print(\"\\nPredicting tags with HMM (MLEProbDist)...\")\n",
    "predicted_mle = [hmm_mle.tag(sentence) for sentence in test_sentences]\n",
    "print(\"Prediction with HMM (MLEProbDist) completed.\")\n",
    "\n",
    "# Model 5: HMM with ELEProbDist\n",
    "print(\"\\nPredicting tags with HMM (ELEProbDist)...\")\n",
    "predicted_ele = [hmm_ele.tag(sentence) for sentence in test_sentences]\n",
    "print(\"Prediction with HMM (ELEProbDist) completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2062661a-cfd1-43c3-a023-cd84fabb4e12",
   "metadata": {
    "id": "2062661a-cfd1-43c3-a023-cd84fabb4e12",
    "tags": []
   },
   "source": [
    "\n",
    "## Model Evaluation\n",
    "\n",
    "Evaluate the performance of our HMM equipped with the Viterbi algorithm to gauge how effectively it handles unseen data. This involves comparing the tags predicted by our model on the test dataset against the actual tags.\n",
    "\n",
    "* Compute Precision, Recall, and F1-score for each tag and the overall model.\n",
    "\n",
    "* Print a confusion matrix that provides insights into the types of errors made by the model and helps in evaluating the accuracy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d84de0e4-5c03-4198-b302-a00b6bfcd0ca",
   "metadata": {
    "id": "d84de0e4-5c03-4198-b302-a00b6bfcd0ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "import itertools\n",
    "\n",
    "def printConfusionMatrix(labels_predicted, labels_correct):\n",
    "    actual_tags = list(itertools.chain(*[[tag for word, tag in sent] for sent in labels_correct]))\n",
    "    predicted_tags = list(itertools.chain(*[[tag for word, tag in sent] for sent in labels_predicted]))\n",
    "    conf_matrix = ConfusionMatrix(actual_tags, predicted_tags)\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b2a831-cb97-4e85-b6fa-8de74718f772",
   "metadata": {
    "id": "00b2a831-cb97-4e85-b6fa-8de74718f772",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries for model evaluation and metrics calculation\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "# Defining the conlleval function for evaluating NLP models\n",
    "def printConlleval(labels_predicted, labels_correct):\n",
    "    lb = LabelBinarizer() # Initializing the LabelBinarizer for handling label encoding\n",
    "\n",
    "    # Flattening the list of labels for correct and predicted\n",
    "    labels_correct_flattened = [(word, tag) for sent in labels_correct for word, tag in sent]\n",
    "    labels_predicted_flattened = [(word, tag) for sent in labels_predicted for word, tag in list(sent)]\n",
    "\n",
    "    # Transforming the labels into a binary format for evaluation\n",
    "    y_true_combined = lb.fit_transform([tag for _, tag in labels_correct_flattened])\n",
    "    y_pred_combined = lb.transform([tag for _, tag in labels_predicted_flattened])\n",
    "\n",
    "    tagset = set(lb.classes_)\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "\n",
    "    num_sentences = len(labels_predicted)\n",
    "    total_tokens = sum(len(s) for s in labels_predicted)\n",
    "\n",
    "    num_correct_sentences, total_correct_tokens = 0, 0\n",
    "    for pred, true in zip(labels_predicted, labels_correct):\n",
    "        if len(pred) == len(true):\n",
    "            correct_tokens = sum(p == t for p, t in zip(pred, true))\n",
    "            total_correct_tokens += correct_tokens\n",
    "            if correct_tokens == len(pred):\n",
    "                num_correct_sentences += 1\n",
    "\n",
    "    correct_sentences_percentage = num_correct_sentences / num_sentences * 100\n",
    "    total_correct_tokens_percentage = total_correct_tokens / total_tokens * 100\n",
    "\n",
    "    classification_report_dict = classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels=[class_indices[cls] for cls in tagset],\n",
    "        target_names=tagset,\n",
    "        output_dict=True,\n",
    "        zero_division=1\n",
    "    )\n",
    "\n",
    "\n",
    "    classification_report_dict.pop('macro avg', None)\n",
    "    classification_report_dict.pop('weighted avg', None)\n",
    "    classification_report_dict.pop('samples avg', None)\n",
    "    classification_report_dict.pop('micro avg', None)\n",
    "\n",
    "    total_precision = precision_score(y_true_combined, y_pred_combined, average='weighted', zero_division=1)\n",
    "    total_recall = recall_score(y_true_combined, y_pred_combined, average='weighted', zero_division=1)\n",
    "    total_f1 = f1_score(y_true_combined, y_pred_combined, average='weighted', zero_division=1)\n",
    "    total_line = f\"{'Total':<15s} {total_precision:<10.2f} {total_recall:<10.2f} {total_f1:<10.2f}\"\n",
    "\n",
    "    report_lines = [f\"{k:<15s} {classification_report_dict[k]['precision']:<10.2f} {classification_report_dict[k]['recall']:<10.2f} {classification_report_dict[k]['f1-score']:<10.2f}\" for k in classification_report_dict if isinstance(classification_report_dict[k], dict)]\n",
    "    report_lines.insert(0, \"\\n\")\n",
    "    report_lines.insert(1, f\"{'TAG':<15s} {'Precision':<10s} {'Recall':<10s} {'F1-score':<10s}\\n\")\n",
    "    report_lines.insert(2, total_line)\n",
    "    report_lines.insert(3, '-'*50 + '\\n')\n",
    "    classification_report_str = \"\\n\".join(report_lines)\n",
    "\n",
    "    additional_info_str = ''\n",
    "    additional_info_str += f'Total tokens: {total_tokens}\\n'\n",
    "    additional_info_str += f'Total correct tokens: {total_correct_tokens} ({total_correct_tokens_percentage:.2f}%)\\n'\n",
    "    additional_info_str += f'Processed sentences: {num_sentences}\\n'\n",
    "    additional_info_str += f'Completely correct sentences: {num_correct_sentences} ({correct_sentences_percentage:.2f}%)\\n'\n",
    "\n",
    "    print(additional_info_str + classification_report_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bde1948-0d1c-4412-9571-0bed92aca0b1",
   "metadata": {
    "id": "3bde1948-0d1c-4412-9571-0bed92aca0b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation for Pure HMM ===\n",
      "Total tokens: 40434\n",
      "Total correct tokens: 23277 (57.57%)\n",
      "Processed sentences: 1875\n",
      "Completely correct sentences: 489 (26.08%)\n",
      "\n",
      "\n",
      "TAG             Precision  Recall     F1-score  \n",
      "\n",
      "Total           0.86       0.58       0.63      \n",
      "--------------------------------------------------\n",
      "\n",
      ".               1.00       0.45       0.62      \n",
      "ADJ             0.93       0.46       0.62      \n",
      "ADP             0.97       0.51       0.67      \n",
      "ADV             0.89       0.54       0.68      \n",
      "CONJ            0.99       0.48       0.65      \n",
      "DET             1.00       0.59       0.74      \n",
      "NOUN            0.97       0.47       0.64      \n",
      "NUM             0.98       0.53       0.69      \n",
      "PRON            0.96       0.67       0.79      \n",
      "PRT             0.88       0.53       0.67      \n",
      "VERB            0.26       0.98       0.41      \n",
      "X               1.00       0.28       0.43      \n",
      "     |                        C         N         P         V      |\n",
      "     |         A    A    A    O    D    O    N    R    P    E      |\n",
      "     |         D    D    D    N    E    U    U    O    R    R      |\n",
      "     |    .    J    P    V    J    T    N    M    N    T    B    X |\n",
      "-----+-------------------------------------------------------------+\n",
      "   . |<2152>   .    .    .    .    .    .    .    .    . 2659    . |\n",
      " ADJ |    .<1423>   .   69    .    .   44    .    .    5 1550    . |\n",
      " ADP |    .    .<2555>  38    4    4    .    .   12   48 2308    . |\n",
      " ADV |    .   38   32 <951>   .    2    1    .    .   13  710    . |\n",
      "CONJ |    .    .    .    . <561>   1    .    .    .    .  607    . |\n",
      " DET |    .    .   13    2    .<2777>   .    .   25    . 1855    . |\n",
      "NOUN |    1   51    1    2    .    1<5246>   8    1    . 5742    . |\n",
      " NUM |    .    .    .    .    .    .    2 <364>   .    .  316    . |\n",
      "PRON |    .    .    4    .    .    3    1    . <851>   .  416    . |\n",
      " PRT |    .    1   38    3    .    .    1    .    . <501> 393    . |\n",
      "VERB |    .    9    1    4    .    .   97    .    .    .<5888>   . |\n",
      "   X |    .    .    .    .    .    1    2    .    .    .   18   <8>|\n",
      "-----+-------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "=== Evaluation for HMM (Lidstone, gamma=0.01) ===\n",
      "Total tokens: 40434\n",
      "Total correct tokens: 37268 (92.17%)\n",
      "Processed sentences: 1875\n",
      "Completely correct sentences: 585 (31.20%)\n",
      "\n",
      "\n",
      "TAG             Precision  Recall     F1-score  \n",
      "\n",
      "Total           0.94       0.92       0.93      \n",
      "--------------------------------------------------\n",
      "\n",
      ".               0.96       0.99       0.98      \n",
      "ADJ             0.88       0.85       0.87      \n",
      "ADP             0.95       0.97       0.96      \n",
      "ADV             0.81       0.86       0.84      \n",
      "CONJ            0.88       1.00       0.93      \n",
      "DET             0.96       0.99       0.97      \n",
      "NOUN            0.97       0.87       0.92      \n",
      "NUM             0.78       0.89       0.83      \n",
      "PRON            0.91       0.98       0.95      \n",
      "PRT             0.85       0.90       0.87      \n",
      "VERB            0.97       0.90       0.93      \n",
      "X               0.03       0.83       0.06      \n",
      "     |                        C         N         P         V      |\n",
      "     |         A    A    A    O    D    O    N    R    P    E      |\n",
      "     |         D    D    D    N    E    U    U    O    R    R      |\n",
      "     |    .    J    P    V    J    T    N    M    N    T    B    X |\n",
      "-----+-------------------------------------------------------------+\n",
      "   . |<4779>   .    .    .    .    .    .    .    .    .    .   32 |\n",
      " ADJ |    8<2635>   3  127   20   31  107   15    3    7   16  119 |\n",
      " ADP |    .    .<4812>  53    9    6    .    .   17   62    4    6 |\n",
      " ADV |    5   78   69<1509>   5    9    6    2    5   31    8   20 |\n",
      "CONJ |    .    .    .    .<1165>   2    .    .    .    .    .    2 |\n",
      " DET |    .    .   22    2    .<4614>   .    .   30    .    .    4 |\n",
      "NOUN |  144  211   11   54   81   78<9627> 143   51   46  140  467 |\n",
      " NUM |    9    9    1    7    5   21    6 <607>   5    .    .   12 |\n",
      "PRON |    .    .   13    .    .    5    2    .<1253>   .    .    2 |\n",
      " PRT |    .    4   73    5    .    .    3    .    4 <841>   5    2 |\n",
      "VERB |   34   42   59  102   40   31  173   15    6    3<5402>  92 |\n",
      "   X |    .    .    .    .    .    2    1    .    1    .    1  <24>|\n",
      "-----+-------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "=== Evaluation for HMM (Lidstone, gamma=0.1) ===\n",
      "Total tokens: 40434\n",
      "Total correct tokens: 34957 (86.45%)\n",
      "Processed sentences: 1875\n",
      "Completely correct sentences: 516 (27.52%)\n",
      "\n",
      "\n",
      "TAG             Precision  Recall     F1-score  \n",
      "\n",
      "Total           0.95       0.86       0.90      \n",
      "--------------------------------------------------\n",
      "\n",
      ".               0.98       0.97       0.98      \n",
      "ADJ             0.89       0.77       0.83      \n",
      "ADP             0.95       0.94       0.95      \n",
      "ADV             0.82       0.81       0.82      \n",
      "CONJ            0.94       0.95       0.94      \n",
      "DET             0.97       0.98       0.97      \n",
      "NOUN            0.97       0.76       0.85      \n",
      "NUM             0.79       0.82       0.80      \n",
      "PRON            0.91       0.96       0.94      \n",
      "PRT             0.86       0.87       0.87      \n",
      "VERB            0.97       0.85       0.91      \n",
      "X               0.01       0.93       0.02      \n",
      "     |                        C         N         P         V      |\n",
      "     |         A    A    A    O    D    O    N    R    P    E      |\n",
      "     |         D    D    D    N    E    U    U    O    R    R      |\n",
      "     |    .    J    P    V    J    T    N    M    N    T    B    X |\n",
      "-----+-------------------------------------------------------------+\n",
      "   . |<4678>   .    .    .    .    .    .    .    .    .    .  133 |\n",
      " ADJ |    5<2388>   3  117   10   19   73   13    3    6   15  439 |\n",
      " ADP |    .    .<4687>  50    6    7    .    .   15   63    4  137 |\n",
      " ADV |    1   75   69<1418>   4    8    6    2    4   28    5  127 |\n",
      "CONJ |    .    .    .    .<1113>   1    .    .    .    .    .   55 |\n",
      " DET |    .    .   22    2    .<4564>   .    .   29    .    .   55 |\n",
      "NOUN |   56  156   15   36   32   55<8386> 122   61   35  120 1979 |\n",
      " NUM |    2    9    .    6    1   15    4 <559>   3    .    1   82 |\n",
      "PRON |    .    .   15    .    .    6    1    .<1230>   .    .   23 |\n",
      " PRT |    .    3   68    5    .    .    4    .    4 <819>   5   29 |\n",
      "VERB |   16   54   50   88   23   45  134   15    5    2<5088> 479 |\n",
      "   X |    .    .    .    .    .    1    .    .    1    .    .  <27>|\n",
      "-----+-------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "=== Evaluation for HMM (MLEProbDist) ===\n",
      "Total tokens: 40434\n",
      "Total correct tokens: 23277 (57.57%)\n",
      "Processed sentences: 1875\n",
      "Completely correct sentences: 489 (26.08%)\n",
      "\n",
      "\n",
      "TAG             Precision  Recall     F1-score  \n",
      "\n",
      "Total           0.86       0.58       0.63      \n",
      "--------------------------------------------------\n",
      "\n",
      ".               1.00       0.45       0.62      \n",
      "ADJ             0.93       0.46       0.62      \n",
      "ADP             0.97       0.51       0.67      \n",
      "ADV             0.89       0.54       0.68      \n",
      "CONJ            0.99       0.48       0.65      \n",
      "DET             1.00       0.59       0.74      \n",
      "NOUN            0.97       0.47       0.64      \n",
      "NUM             0.98       0.53       0.69      \n",
      "PRON            0.96       0.67       0.79      \n",
      "PRT             0.88       0.53       0.67      \n",
      "VERB            0.26       0.98       0.41      \n",
      "X               1.00       0.28       0.43      \n",
      "     |                        C         N         P         V      |\n",
      "     |         A    A    A    O    D    O    N    R    P    E      |\n",
      "     |         D    D    D    N    E    U    U    O    R    R      |\n",
      "     |    .    J    P    V    J    T    N    M    N    T    B    X |\n",
      "-----+-------------------------------------------------------------+\n",
      "   . |<2152>   .    .    .    .    .    .    .    .    . 2659    . |\n",
      " ADJ |    .<1423>   .   69    .    .   44    .    .    5 1550    . |\n",
      " ADP |    .    .<2555>  38    4    4    .    .   12   48 2308    . |\n",
      " ADV |    .   38   32 <951>   .    2    1    .    .   13  710    . |\n",
      "CONJ |    .    .    .    . <561>   1    .    .    .    .  607    . |\n",
      " DET |    .    .   13    2    .<2777>   .    .   25    . 1855    . |\n",
      "NOUN |    1   51    1    2    .    1<5246>   8    1    . 5742    . |\n",
      " NUM |    .    .    .    .    .    .    2 <364>   .    .  316    . |\n",
      "PRON |    .    .    4    .    .    3    1    . <851>   .  416    . |\n",
      " PRT |    .    1   38    3    .    .    1    .    . <501> 393    . |\n",
      "VERB |    .    9    1    4    .    .   97    .    .    .<5888>   . |\n",
      "   X |    .    .    .    .    .    1    2    .    .    .   18   <8>|\n",
      "-----+-------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "=== Evaluation for HMM (ELEProbDist) ===\n",
      "Total tokens: 40434\n",
      "Total correct tokens: 26037 (64.39%)\n",
      "Processed sentences: 1875\n",
      "Completely correct sentences: 262 (13.97%)\n",
      "\n",
      "\n",
      "TAG             Precision  Recall     F1-score  \n",
      "\n",
      "Total           0.95       0.64       0.75      \n",
      "--------------------------------------------------\n",
      "\n",
      ".               1.00       0.89       0.94      \n",
      "ADJ             0.89       0.45       0.60      \n",
      "ADP             0.95       0.74       0.83      \n",
      "ADV             0.83       0.58       0.68      \n",
      "CONJ            0.96       0.75       0.84      \n",
      "DET             0.98       0.89       0.93      \n",
      "NOUN            0.98       0.45       0.61      \n",
      "NUM             0.80       0.48       0.60      \n",
      "PRON            0.87       0.83       0.85      \n",
      "PRT             0.88       0.72       0.79      \n",
      "VERB            0.98       0.60       0.74      \n",
      "X               0.00       0.97       0.00      \n",
      "     |                        C         N         P         V      |\n",
      "     |         A    A    A    O    D    O    N    R    P    E      |\n",
      "     |         D    D    D    N    E    U    U    O    R    R      |\n",
      "     |    .    J    P    V    J    T    N    M    N    T    B    X |\n",
      "-----+-------------------------------------------------------------+\n",
      "   . |<4278>   .    .    .    .    .    .    .    .    .    .  533 |\n",
      " ADJ |    1<1388>   5   93    5    7   36    7    2    2   16 1529 |\n",
      " ADP |    .    .<3685>  35    3   12    .    .   14   55    4 1161 |\n",
      " ADV |    .   41   53<1012>   1    7    3    2    5   23    4  596 |\n",
      "CONJ |    .    .    .    . <880>   .    .    .    .    .    .  289 |\n",
      " DET |    .    .   21    2    .<4169>   .    .   26    .    .  454 |\n",
      "NOUN |   13   90   15   23   13   39<4936>  61  103   13   50 5697 |\n",
      " NUM |    1    5    3    2    .    1    1 <330>   .    .    .  339 |\n",
      "PRON |    .    .    6    .    .    4    1    .<1064>   .    .  200 |\n",
      " PRT |    .    .   55    5    .    .    1    .    5 <674>   5  192 |\n",
      "VERB |    6   30   35   50   13   24   62   14    6    2<3593>2164 |\n",
      "   X |    .    .    .    .    .    .    .    .    1    .    .  <28>|\n",
      "-----+-------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The correct labels are the tags from test_sents\n",
    "labels_correct = test_sents\n",
    "\n",
    "# Evaluate each model using printContLevel and printConfusionMatrix\n",
    "# Model 1: Pure HMM\n",
    "print(\"\\n=== Evaluation for Pure HMM ===\")\n",
    "printConlleval(predicted_pure, labels_correct)\n",
    "printConfusionMatrix(predicted_pure, labels_correct)\n",
    "\n",
    "# Model 2: HMM with Lidstone smoothing (gamma=0.01)\n",
    "print(\"\\n=== Evaluation for HMM (Lidstone, gamma=0.01) ===\")\n",
    "printConlleval(predicted_lidstone_001, labels_correct)\n",
    "printConfusionMatrix(predicted_lidstone_001, labels_correct)\n",
    "\n",
    "# Model 3: HMM with Lidstone smoothing (gamma=0.1)\n",
    "print(\"\\n=== Evaluation for HMM (Lidstone, gamma=0.1) ===\")\n",
    "printConlleval(predicted_lidstone_01, labels_correct)\n",
    "printConfusionMatrix(predicted_lidstone_01, labels_correct)\n",
    "\n",
    "# Model 4: HMM with MLEProbDist\n",
    "print(\"\\n=== Evaluation for HMM (MLEProbDist) ===\")\n",
    "printConlleval(predicted_mle, labels_correct)\n",
    "printConfusionMatrix(predicted_mle, labels_correct)\n",
    "\n",
    "# Model 5: HMM with ELEProbDist\n",
    "print(\"\\n=== Evaluation for HMM (ELEProbDist) ===\")\n",
    "printConlleval(predicted_ele, labels_correct)\n",
    "printConfusionMatrix(predicted_ele, labels_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e5e5b6-508d-4741-a764-2454c1edf025",
   "metadata": {
    "id": "48e5e5b6-508d-4741-a764-2454c1edf025"
   },
   "source": [
    "## Choose the best model\n",
    "\n",
    "Choose the best model and export it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18a285a5-c694-47af-94f1-49074d150a53",
   "metadata": {
    "id": "18a285a5-c694-47af-94f1-49074d150a53",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing dill library for model serialization\n",
    "import dill\n",
    "mybestmodel = hmm_lidstone_001\n",
    "\n",
    "# serialization with dill\n",
    "with open('mybestmodel.dill', 'wb') as file:\n",
    "    dill.dump(mybestmodel, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
